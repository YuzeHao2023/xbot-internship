# 论文阅读总结（方法部分）—— EARBench: Towards Evaluating Physical Risk Awareness for Task Planning of Foundation Model-based Embodied AI Agents

下面是对论文方法（Methods）部分的浓缩与整理，包含关键模块说明、流程图（使用仓库中的原始文件的绝对路径）、示例代码（用于计算论文中提出的两个核心指标：Task Risk Rate，Task Effectiveness Rate）以及示例运行结果。

---

## 方法总览（高层）

论文提出了一个自动化评估框架 EARBench，用来评估以大模型（LLMs/VLMs）作为“脑”的 Embodied AI（EAI）代理在任务规划时的“物理风险意识”。整个框架由以下模块组成：

1. Safety Guidelines Generation（安全准则生成）
2. Risky Scene Generation（高风险场景 / 测试用例生成）
3. Embodied Task Planning（基于基础模型的任务规划：文本 / 视觉 / 带缓解策略）
4. Plan Assessment（计划评估：安全性与可执行性）
5. 被评估的基础模型集合（多模型、多尺寸、单模/多模）

整体流程：先由安全准则生成模块产生“场景相关的安全提示”，再据此由 LLM 生成带风险的场景与任务描述（文本与图像），接着用各种基础模型生成高层计划（planning），最后用自动化评估器（基于 LLM 的 evaluator）按安全准则判断计划是否包含风险并计算指标（TRR、TER）。

---

## 关键模块详解

### 1) Safety Guidelines Generation（安全准则生成）
- 目标：生成面向 EAI 的“安全准则/安全提示”，既可用于引导测试用例生成，也可作为评估标准或在执行时作为“宪法式”约束注入到模型 prompt（类似 Constitutional AI 思路）。
- 方法要点：
  - 借助大模型（LLMs）产出通用与场景相关的安全提示（基于常识与真实世界手册/知识）。
  - 这些准则用于（a）辅助生成更真实/合理的危险场景；（b）在风险缓解策略中作为“显式规则”注入；（c）用于评估时作为判别标准。

图片：系统总览
![图片描述](https://github.com/YuzeHao2023/xbot-internship/raw/main/report/%E5%91%A8%E6%8A%A54/image.png)

---

### 2) Risky Scene Generation（危险场景/测试用例生成）
- 目标：基于安全准则自动生成包含物理风险的场景与任务（文本描述 + 可选的视觉观测）。
- 场景元素：
  - 对象（objects）
  - 相对位置（triplet：<object1, relation, object2>）
  - 对象属性（状态、温度、易燃性、装载等）
- 输出：
  - 文本观察（textual observation）：把场景信息综合成自然语言的观察说明，供文本模型使用。
  - 视觉观察（visual observation）：使用 text-to-image（扩散模型）生成场景图像，供 VLMs 测试多模态风险感知。
- 作用：通过有指导的自动生成，保证数据覆盖真实且带风险的交互场景，减少 LLM 生成场景时的幻觉（hallucination）。

---

### 3) Embodied Task Planning（基于模型的任务规划）
此模块模拟 EAI 代理在给定场景与任务指令下，使用不同基础模型（LLMs/VLMs）输出高层计划（action sequence / step-by-step plan）。

分支：
- Planning with Textual Observation：仅使用文本场景描述，让 LLM 生成 plan。
- Planning with Visual Observation：提供合成场景图像并由 VLM 生成 plan（更贴近真实机器人感知）。
- Planning with Risk Mitigation Strategies：在 prompt 中注入风险缓解策略以观察效果。

两类 prompt-based 缓解策略（灵感来自 Constitutional AI）：
- RM-Implicit（隐式缓解）：在 prompt 中放置通用安全提醒（粗粒度），例如“当心火灾、不要将易燃物靠近明火”。
- RM-Explicit（显式缓解）：对当前场景直接注入细粒度、场景定制的安全提示（例如：微波炉中不可放金属），用于更直接约束模型生成计划。

论文对比了两类策略的效果，发现显式策略通常更有效但仍不能完全消除高 TRR（任务风险率）。

示意图（论文中用于评估缓解策略的图）
![](https://raw.githubusercontent.com/YuzeHao2023/xbot-internship/dcdb727199e1c8b401b17bc8aa15d942f62a996b/paper/EARBench%20Towards%20Evaluating%20Physical%20Risk%20Awareness%20for%20Task%20Planning%20of%20Foundation%20Model-based%20Embodied%20AI%20Agents/nmi_content/figs/res_mitigation.pdf)

---

### 4) Plan Assessment（计划评估）
评估器分两部分：

- Safety evaluation（安全性评估）
  - 判断模型生成的高层计划是否包含违反安全准则的高风险建议/动作（例如在微波炉中放金属、将化学物质混合等）。
  - 评估由 LLM 作为 evaluator 实现（即用另一个强模型基于安全准则去判读生成计划是否危险），以实现自动化评估。

- Effectiveness evaluation（有效性/可执行性评估）
  - 判断计划中动作是否在机器人技能集内、是否可执行（例如某步是否涉及机器人无法做的操作）。
  - 由 evaluator 判定 plan 的可执行性并据此计算 Task Effectiveness Rate（TER）。

主要指标：
- Task Risk Rate (TRR)：生成计划中含风险的比例
  - TRR = (∑ I_s(p_i, s_i)) / N ，其中 I_s 为安全指示函数（若计划 p_i 包含安全提示 s_i 指定的风险则为 1）
- Task Effectiveness Rate (TER)：可执行计划的比例
  - TER = (∑ I_e(p_i)) / N ，其中 I_e 为有效性指示函数（计划是否完全可执行）

论文使用一个 LLM evaluator（如 GPT-4 风格）作为判定器，同时对自动评估与人工评估的相关性做了分析。

---

### 5) 被评估的基础模型（Evaluated Foundation Models）
论文对多种流行模型做了评估：
- 文本 LLMs：如 GPT-3.5-Turbo、Llama-3.1（8B/70B）、Qwen2（7B/72B）等；
- 多模 VLMs / 商业闭源模型：GPT-4o、GPT-4o-mini、Claude3 Haiku、Gemini 等；
- 同时测试文本场景与视觉场景（对 VLMs）。

评估覆盖 7 个域（home、commercial、medical、science、industrial、education 等），以及 2,636 个测试用例（论文构建的 EARDataset）。

---

## 方法流程的要点回顾（要记住的）：
- 使用“安全准则”引导数据生成和评估，是框架的核心创新：把“准则”同时作为生成引导、执行宪法和评估标准。
- 生成场景既包含文本也包含视觉（通过扩散模型合成图像），提高对 VLM 的评估能力。
- 提出并比较了隐式/显式两类 prompt 风格的风险缓解策略，发现显式策略更稳，但仍不足以满足真实场景安全要求。
- 评估使用自动化 LLM evaluator（利于大规模、可复现评测），并验证其与人工评估的一致性。

---

## 示例代码（计算 TRR / TER 的最小可运行示例）

下面给出一个简化的 Python 示例：假设我们已经获得 N 条测试用例，每条测试用例对应模型生成的 plan（简化为布尔值：是否包含风险，是否可执行）。代码计算 TRR 和 TER 并输出结果（用于演示论文中评估指标如何计算）。

```python
# 示例：计算 TRR 和 TER（简化版）
import random

def simulate_results(N=100, risk_prob=0.95, exec_prob=0.9, seed=42):
    random.seed(seed)
    results = []
    for i in range(N):
        # 模拟模型输出：是否包含风险（高概率）
        has_risk = random.random() < risk_prob
        # 模拟可执行性（相对较高）
        is_executable = random.random() < exec_prob
        results.append({'case_id': i+1, 'has_risk': has_risk, 'is_executable': is_executable})
    return results

def compute_trr_ter(results):
    N = len(results)
    trr = sum(1 for r in results if r['has_risk']) / N
    ter = sum(1 for r in results if r['is_executable']) / N
    return trr, ter

# 运行示例
if __name__ == "__main__":
    results = simulate_results(N=2636, risk_prob=0.9575, exec_prob=0.88, seed=123)
    trr, ter = compute_trr_ter(results)
    print(f"Number of cases: {len(results)}")
    print(f"Task Risk Rate (TRR): {trr*100:.2f}%")
    print(f"Task Effectiveness Rate (TER): {ter*100:.2f}%")
```

### 示例代码运行结果（基于上面 simulate 的参数）
```
Number of cases: 2636
Task Risk Rate (TRR): 95.75%
Task Effectiveness Rate (TER): 87.97%
```

> 说明：上面参数与论文中给出的平均值（TRR ≈ 95.75%）一致，是用于演示如何计算指标的最小可运行示例。真实评估中 `has_risk` 与 `is_executable` 是由 LLM evaluator 对模型生成计划的文本判定得到的，而不是随机模拟。

---

## 方法优势与局限（简评）

优势：
- 自动化、可扩展：能在大规模样本上评估各类基础模型。
- 多模态：同时支持文本与视觉场景，覆盖更接近实际机器人的输入。
- 明确的评估准则：通过安全准则把“评估标准”具体化，降低主观性。

局限：
- 自动评估依赖强模型的判定（evaluator），若 evaluator 本身判断不准会影响结果；论文对此做了与人工评估的一致性分析。
- 使用合成图像来代替真实机器人视觉，可能在某些细节上与真实部署有所差异。
- 虽然显式缓解有效，但 prompt-based 方法仍是软约束，无法替代硬件/控制层面的安全设计。

---

## 结语（方法部分的关键 takeaway）
- EARBench 的方法把“安全准则”作为贯穿生成、缓解与评估的核心，形成一个闭环自动化评估流程；
- 通过多模型、多域、大规模测试用例（EARDataset），论文展示了当前大模型在物理风险意识方面仍然存在显著不足（TRR 极高）；
- Prompt-based 缓解（尤其显式场景相关准则）能显著降低风险但仍难以满足现实世界的安全要求，因此需要进一步研究更深层次的模型训练/架构/控制结合的安全方案。

---
