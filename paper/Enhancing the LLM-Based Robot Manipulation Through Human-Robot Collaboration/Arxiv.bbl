% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{vaswani2023attention}
A.~Vaswani \emph{et~al.}, ``Attention is all you need,'' \emph{arXiv preprint arXiv:1706.03762}, 2023.

\bibitem{touvron2023llama}
H.~Touvron \emph{et~al.}, ``Llama: Open and efficient foundation language models,'' \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{saycan2022arxiv}
M.~Ahn \emph{et~al.}, ``Do as i can and not as i say: Grounding language in robotic affordances,'' in \emph{arXiv preprint arXiv:2204.01691}, 2022.

\bibitem{wu2023tidybot}
J.~Wu \emph{et~al.}, ``Tidybot: Personalized robot assistance with large language models,'' \emph{Autonomous Robots}, 2023.

\bibitem{redmon2016look}
J.~Redmon, S.~Divvala, R.~Girshick, and A.~Farhadi, ``You only look once: Unified, real-time object detection,'' \emph{arXiv preprint arXiv:1506.02640}, 2016.

\bibitem{radford2021learning}
A.~Radford \emph{et~al.}, ``Learning transferable visual models from natural language supervision,'' \emph{arXiv preprint arXiv:2103.00020}, 2021.

\bibitem{kirillov2023segment}
A.~Kirillov \emph{et~al.}, ``Segment anything,'' \emph{arXiv preprint arXiv:2304.02643}, 2023.

\bibitem{singh2023progprompt}
I.~Singh \emph{et~al.}, ``Progprompt: Generating situated robot task plans using large language models,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 11\,523--11\,530.

\bibitem{zhao2023differentiable}
Z.~Zhao, W.~S. Lee, and D.~Hsu, ``Differentiable parsing and visual grounding of natural language instructions for object placement,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 11\,546--11\,553.

\bibitem{liang2023code}
J.~Liang \emph{et~al.}, ``Code as policies: Language model programs for embodied control,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 9493--9500.

\bibitem{10341846}
J.~Liu, Z.~Li, W.~Lin, S.~Calinon, K.~C. Tan, and F.~Chen, ``Softgpt: Learn goal-oriented soft object manipulation skills by generative pre-trained heterogeneous graph transformer,'' in \emph{2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2023, pp. 4920--4925.

\bibitem{10160906}
W.~Wang, X.~Li, Y.~Dong, J.~Xie, D.~Guo, and H.~Liu, ``Natural language instruction understanding for robotic manipulation: a multisensory perception approach,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}, 2023, pp. 9800--9806.

\bibitem{goertz1964manipulator}
R.~C. Goertz, ``Manipulator systems developed at anl,'' in \emph{Proceedings, The 12th Conference on Remote Systems Technology}, 1964, pp. 117--136.

\bibitem{nakanishi2020towards}
J.~Nakanishi, S.~Itadera, T.~Aoyama, and Y.~Hasegawa, ``Towards the development of an intuitive teleoperation system for human support robot using a vr device,'' \emph{Advanced Robotics}, vol.~34, no.~19, pp. 1239--1253, 2020.

\bibitem{zhu2020enhancing}
Y.~Zhu, T.~Aoyama, and Y.~Hasegawa, ``Enhancing the transparency by onomatopoeia for passivity-based time-delayed teleoperation,'' \emph{IEEE Robotics and Automation Letters}, vol.~5, no.~2, pp. 2981--2986, 2020.

\bibitem{10173494}
Y.~Zhu, B.~Jiang, Q.~Chen, T.~Aoyama, and Y.~Hasegawa, ``A shared control framework for enhanced grasping performance in teleoperation,'' \emph{IEEE Access}, vol.~11, pp. 69\,204--69\,215, 2023.

\bibitem{lenz2023nimbro}
C.~Lenz \emph{et~al.}, ``Nimbro wins ana avatar xprize immersive telepresence competition: Human-centric evaluation and lessons learned,'' \emph{International Journal of Social Robotics}, pp. 1--25, 2023.

\bibitem{schaal2006dynamic}
S.~Schaal, ``Dynamic movement primitives-a framework for motor control in humans and humanoid robotics,'' in \emph{Adaptive motion of animals and machines}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2006, pp. 261--280.

\bibitem{ijspeert2013dynamical}
A.~J. Ijspeert, J.~Nakanishi, H.~Hoffmann, P.~Pastor, and S.~Schaal, ``Dynamical movement primitives: learning attractor models for motor behaviors,'' \emph{Neural computation}, vol.~25, no.~2, pp. 328--373, 2013.

\bibitem{paraschos2013probabilistic}
A.~Paraschos, C.~Daniel, J.~R. Peters, and G.~Neumann, ``Probabilistic movement primitives,'' \emph{Advances in neural information processing systems}, vol.~26, 2013.

\bibitem{10050558}
G.~Li, Z.~Jin, M.~Volpp, F.~Otto, R.~Lioutikov, and G.~Neumann, ``Prodmp: A unified perspective on dynamic and probabilistic movement primitives,'' \emph{IEEE Robotics and Automation Letters}, vol.~8, no.~4, pp. 2325--2332, 2023.

\end{thebibliography}
